{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"colab":{"name":"Copy of bert_with_fastai.ipynb","provenance":[{"file_id":"https://github.com/keitakurita/Practical_NLP_in_PyTorch/blob/master/fastai/bert_with_fastai.ipynb","timestamp":1578294406852}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"Y3Y4IjKZrVyj","colab_type":"text"},"source":["In this notebook, we'll be exploring how to use BERT with fastai for sentence classification."]},{"cell_type":"code","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","id":"TcpaHm9vrVym","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","\n","from pathlib import Path\n","from typing import *\n","\n","import torch\n","import torch.optim as optim"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BRRt1gHFrVyq","colab_type":"code","colab":{}},"source":["from fastai import *\n","from fastai.vision import *\n","from fastai.text import *\n","from fastai.callbacks import *"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QtoJEJh4rVyt","colab_type":"code","colab":{}},"source":["class Config(dict):\n","    def __init__(self, **kwargs):\n","        super().__init__(**kwargs)\n","        for k, v in kwargs.items():\n","            setattr(self, k, v)\n","    \n","    def set(self, key, val):\n","        self[key] = val\n","        setattr(self, key, val)\n","\n","config = Config(\n","    testing=False,\n","    bert_model_name=\"bert-base-uncased\",\n","    max_lr=3e-5,\n","    epochs=1,\n","    use_fp16=False,\n","    bs=4,\n","    discriminative=False,\n","    max_seq_len=128,\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BEIzshSTrVyw","colab_type":"text"},"source":["We'll be using the pytorch-pretrained-bert package, so install it if you do not have it yet!"]},{"cell_type":"markdown","metadata":{"id":"qtwFUt6srVyx","colab_type":"text"},"source":["BERT requires a special wordpiece tokenizer and a vocabulary to go along with that. Thankfully, the pytorch-pretrained-bert package provides all of that within the handy `BertTokenizer` class.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"KVpjbqW3rmhR","colab_type":"code","colab":{}},"source":["!pip install pytorch_pretrained_bert"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pMFGou2ZrVyy","colab_type":"text"},"source":["# Data"]},{"cell_type":"markdown","metadata":{"id":"zUaLVvuTXI0O","colab_type":"text"},"source":["BERT使用自己的词件标记器。\n","BERT需要将[CLS]和[SEP]令牌添加到每个序列。\n","BERT使用自己的预建词汇表。\n","让我们看一下如何处理这些问题。\n","\n","使用字词标记器并处理特殊标记\n","\n","编写我们自己的词件标记器并处理从词件到id的映射将是一个很大的麻烦。幸运的是，出色的pytorch-pretrained-bert软件包在其BertTokenizer中为我们提供了所有必要的信息。"]},{"cell_type":"code","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","id":"n5YSyYBrrVyz","colab_type":"code","outputId":"558810e6-054a-45b8-f191-7700b03a89ee","executionInfo":{"status":"ok","timestamp":1578310705075,"user_tz":-480,"elapsed":13379,"user":{"displayName":"M M","photoUrl":"","userId":"00154079742193433602"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["\n","from pytorch_pretrained_bert import BertTokenizer\n","bert_tok = BertTokenizer.from_pretrained(\n","    config.bert_model_name,\n",")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 231508/231508 [00:00<00:00, 430829.40B/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"XKp9zsGTrVy3","colab_type":"text"},"source":["FastAI has its own conventions for handling tokenization, so we'll need to wrap the tokenizer within a different class. This is a bit confusing but shouldn't be that much of a hassle.\n","\n","Notice we add the \\[CLS] and \\[SEP] special tokens to the start and end of the sequence here.\n","\n","BERT具有多种风格，因此我们为类传递了将要使用的BERT模型的名称（在本文中，我们将使用无大小写的较小版本）。\n","\n","Fastai有关于标记化的内部约定，因此我们将此标记化器包装在其自己的Tokenizer类中。这有点令人困惑，但不应该太麻烦。\n","Fastai有关于标记化的内部约定，因此我们将此标记化器包装在其自己的Tokenizer类中。这有点令人困惑，但不应该太麻烦。"]},{"cell_type":"code","metadata":{"id":"ZZkFDjqCrVy3","colab_type":"code","colab":{}},"source":["class FastAiBertTokenizer(BaseTokenizer):\n","    \"\"\"Wrapper around BertTokenizer to be compatible with fast.ai\"\"\"\n","    def __init__(self, tokenizer: BertTokenizer, max_seq_len: int=128, **kwargs):\n","        self._pretrained_tokenizer = tokenizer\n","        self.max_seq_len = max_seq_len\n","\n","    def __call__(self, *args, **kwargs):\n","        return self\n","\n","    def tokenizer(self, t:str) -> List[str]:\n","        \"\"\"Limits the maximum sequence length\"\"\"\n","        return [\"[CLS]\"] + self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2] + [\"[SEP]\"]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qd707iUrrVy5","colab_type":"text"},"source":["Slightly confusingly, we further need to wrap the tokenizer above in a `Tokenizer` object. \n","如您所见，我们将在此处添加[CLS]和[SEP]令牌，并限制令牌化序列的长度。 \n","\n","有点令人困惑，我们需要将以上代码包装在另一个Tokenizer中，以传递给预处理器。"]},{"cell_type":"code","metadata":{"id":"aM7PMxFDrVy6","colab_type":"code","colab":{}},"source":["fastai_tokenizer = Tokenizer(tok_func=FastAiBertTokenizer(bert_tok, max_seq_len=config.max_seq_len), pre_rules=[], post_rules=[])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HQaAvDMNrVy8","colab_type":"text"},"source":["Now, we need to make sure fastai uses the same mapping from wordpiece to integer as BERT originally did. Again, fastai has its own conventions on vocabulary so we'll be passing the vocabulary internal to the `BertTokenizer` and constructing a fastai `Vocab` object to use for preprocessing.\n","\n","使用BERT词汇\n","\n","bert令牌生成器还包含词汇，作为从单词到id的字典映射。与令牌生成器一样，由于fastai具有自己的词汇约定，因此我们需要根据bert词汇构造一个fastai Vocab对象。幸运的是，这很简单–我们可以简单地通过在词汇表中传递标记列表来做到这一点。"]},{"cell_type":"code","metadata":{"id":"EJEx3E8urVy8","colab_type":"code","colab":{}},"source":["fastai_bert_vocab = Vocab(list(bert_tok.vocab.keys()))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-aUlMxDVrVzB","colab_type":"text"},"source":["Now we have all the pieces we need to make BERT work with fastai! We'll load the data into dataframes and construct a validation set.\n","\n","放在一起\n","\n","现在，我们拥有构建数据束所需的一切。在本教程中，我们将从数据帧构建数据绑定，但是有多种加载数据的方法（请参阅官方文档）。\n","\n","首先，我们使用熊猫将数据加载到数据帧中，并在其中处理验证集。"]},{"cell_type":"code","metadata":{"id":"IE9JDB3MrVzB","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","\n","DATA_ROOT = Path(\"\") / \"data\" / \"jigsaw\"\n","\n","train, test = [pd.read_csv(DATA_ROOT / fname) for fname in [\"traindata.csv\", \"testdata.csv\"]]\n","train, val = train_test_split(train)\n","\n","if config.testing:\n","    train = train.head(1024)\n","    val = val.head(1024)\n","    test = test.head(1024)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bn-CIvwsrVzD","colab_type":"text"},"source":["Now, we can build the databunch using the tokenizer and vocabulary we build above. Notice we're passing the `include_bos=False` and `include_eos=False` options. This is to prevent fastai from adding its own SOS/EOS tokens that will interfere with BERT's SOS/EOS tokens.\n","\n","现在，我们在TextDataBunch上调用from_df方法\n","注意，我们传递了include_bos = False和include_eos = False选项。这是因为fastai默认情况下会添加自己的bos和eos令牌，这会干扰BERT添加的[CLS]和[SEP]令牌。请注意，此选项是新选项，可能不适用于旧版本的fastai。"]},{"cell_type":"code","metadata":{"id":"ytVIuEWQrVzE","colab_type":"code","outputId":"97d7afdf-c39e-42a4-d1d9-802830946135","executionInfo":{"status":"ok","timestamp":1578313086475,"user_tz":-480,"elapsed":7676,"user":{"displayName":"M M","photoUrl":"","userId":"00154079742193433602"}},"colab":{"base_uri":"https://localhost:8080/","height":16}},"source":["label_cols = [\"THEORETICAL\", \"ENGINEERING\", \"EMPIRICAL\", \"OTHERS\"]\n","\n","databunch = TextDataBunch.from_df(\".\", train, val, test,\n","                  tokenizer=fastai_tokenizer,\n","                  vocab=fastai_bert_vocab,\n","                  include_bos=False,\n","                  include_eos=False,\n","                  text_cols=\"Title\",\n","                  label_cols=label_cols,\n","                  bs=config.bs,\n","                  collate_fn=partial(pad_collate, pad_first=False, pad_idx=0),\n","             )"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"O4wcmSZlrVzF","colab_type":"text"},"source":["Alternatively, we can pass our own list of Preprocessors to the databunch (this is effectively what is happening behind the scenes)\n","\n","\n","\n","让我们更深入地了解幕后到底发生了什么。上面的代码使用词片标记器和BERT词汇表初始化TokenizerProcessor和NumericizeProcessor，然后将其应用于数据框中的每个文本。\n","\n","实际上，我们还可以初始化自己的TokenizerProcessor和NumericizeProcessor并将它们传递给数据束，而不是传递配置。"]},{"cell_type":"code","metadata":{"id":"PAEOpft6rVzG","colab_type":"code","colab":{}},"source":["class BertTokenizeProcessor(TokenizeProcessor):\n","    def __init__(self, tokenizer):\n","        super().__init__(tokenizer=tokenizer, include_bos=False, include_eos=False)\n","\n","class BertNumericalizeProcessor(NumericalizeProcessor):\n","    def __init__(self, *args, **kwargs):\n","        super().__init__(*args, vocab=Vocab(list(bert_tok.vocab.keys())), **kwargs)\n","\n","def get_bert_processor(tokenizer:Tokenizer=None, vocab:Vocab=None):\n","    \"\"\"\n","    Constructing preprocessors for BERT\n","    We remove sos/eos tokens since we add that ourselves in the tokenizer.\n","    We also use a custom vocabulary to match the numericalization with the original BERT model.\n","    \"\"\"\n","    return [BertTokenizeProcessor(tokenizer=tokenizer),\n","            NumericalizeProcessor(vocab=vocab)]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qz-NAq1qrVzJ","colab_type":"text"},"source":["To use our own custom preprocessors, we'll need to modify the `from_df` method to call the function above. Not the cleanest code but it will suffice.\n","\n","我们只是包装标记器和词汇表，然后将它们放到管道中以预处理文本。要使用此管道，我们需要稍微修改数据绑定代码以在内部调用get_bert_processor。\n"]},{"cell_type":"code","metadata":{"id":"jL4rjECBrVzK","colab_type":"code","colab":{}},"source":["class BertDataBunch(TextDataBunch):\n","    @classmethod\n","    def from_df(cls, path:PathOrStr, train_df:DataFrame, valid_df:DataFrame, test_df:Optional[DataFrame]=None,\n","                tokenizer:Tokenizer=None, vocab:Vocab=None, classes:Collection[str]=None, text_cols:IntsOrStrs=1,\n","                label_cols:IntsOrStrs=0, label_delim:str=None, **kwargs) -> DataBunch:\n","        \"Create a `TextDataBunch` from DataFrames.\"\n","        p_kwargs, kwargs = split_kwargs_by_func(kwargs, get_bert_processor)\n","        # use our custom processors while taking tokenizer and vocab as kwargs\n","        processor = get_bert_processor(tokenizer=tokenizer, vocab=vocab, **p_kwargs)\n","        if classes is None and is_listy(label_cols) and len(label_cols) > 1: classes = label_cols\n","        src = ItemLists(path, TextList.from_df(train_df, path, cols=text_cols, processor=processor),\n","                        TextList.from_df(valid_df, path, cols=text_cols, processor=processor))\n","        src = src.label_for_lm() if cls==TextLMDataBunch else src.label_from_df(cols=label_cols, classes=classes)\n","        if test_df is not None: src.add_test(TextList.from_df(test_df, path, cols=text_cols))\n","        return src.databunch(**kwargs)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fHlwPUBbrVzM","colab_type":"code","colab":{}},"source":["# 现在，我们可以像这样构建数据仓库。\n","# this will produce a virtually identical databunch to the code above\n","# databunch = BertDataBunch.from_df(\".\", train, val, test,\n","#                   tokenizer=fastai_tokenizer,\n","#                   vocab=fastai_bert_vocab,\n","#                   text_cols=\"comment_text\",\n","#                   label_cols=label_cols,\n","#                   bs=config.bs,\n","#                   collate_fn=partial(pad_collate, pad_first=False, pad_idx=0),\n","#              )"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YZcP7sIQrVzO","colab_type":"text"},"source":["# Model"]},{"cell_type":"markdown","metadata":{"id":"4Cj0DyZprVzP","colab_type":"text"},"source":["Now with the data in place, we will prepare the model and loss functions. Again, the pytorch-pretrained-bert package gives us a sequence classifier based on BERT straight out of the box."]},{"cell_type":"code","metadata":{"id":"hh3WsGFsrVzP","colab_type":"code","colab":{}},"source":["from pytorch_pretrained_bert.modeling import BertConfig, BertForSequenceClassification\n","bert_model = BertForSequenceClassification.from_pretrained(config.bert_model_name, num_labels=4)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QsAdqeh3rVzS","colab_type":"text"},"source":["Since this is a multilabel classification problem, we're using `BCEWithLogitsLoss`"]},{"cell_type":"code","metadata":{"id":"m6P4B36OrVzS","colab_type":"code","colab":{}},"source":["loss_func = nn.BCEWithLogitsLoss()\n","#about bcewithlogistloss https://blog.csdn.net/qq_22210253/article/details/85222093"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qx9BByd6rVzU","colab_type":"text"},"source":["And now we can build the `Learner`."]},{"cell_type":"code","metadata":{"id":"9TCLwUEtrVzV","colab_type":"code","colab":{}},"source":["from fastai.callbacks import *\n","\n","learner = Learner(\n","    databunch, bert_model,\n","    loss_func=loss_func,\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jkIOLiDirVzY","colab_type":"text"},"source":["And we're done! All the rest is fastai magic. For example, you can use half-precision training simply by calling `learner.to_fp16()`"]},{"cell_type":"code","metadata":{"id":"5CpGGmZXrVzZ","colab_type":"code","colab":{}},"source":["#我们还可以利用fastai必须提供的其他一些功能。例如，我们可以通过以下代码轻松地使用半精度训练。\n","if config.use_fp16: learner = learner.to_fp16()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-bCB6qxYrVzc","colab_type":"text"},"source":["We can also use the learning rate finder."]},{"cell_type":"code","metadata":{"id":"wrYjIlaOrVzc","colab_type":"code","outputId":"7c7ceec7-61ca-4e9e-eb94-f74de535471f","executionInfo":{"status":"ok","timestamp":1578313288274,"user_tz":-480,"elapsed":209292,"user":{"displayName":"M M","photoUrl":"","userId":"00154079742193433602"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["learner.lr_find()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RQNYqxdKrVze","colab_type":"code","outputId":"2d06cbd8-c774-4f2e-80b7-20e1f3e498b7","executionInfo":{"status":"ok","timestamp":1578313288723,"user_tz":-480,"elapsed":209726,"user":{"displayName":"M M","photoUrl":"","userId":"00154079742193433602"}},"colab":{"base_uri":"https://localhost:8080/","height":278}},"source":["learner.recorder.plot()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEIiIZDkFgYhIllMQiIhkuf8Pa9p87M34CVcAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"NZtLjOlNrVzg","colab_type":"text"},"source":["And now to actually train the model."]},{"cell_type":"code","metadata":{"id":"OHG-zlrUrVzh","colab_type":"code","outputId":"4c5ffe29-296d-4c59-8164-4fd402efc498","colab":{"base_uri":"https://localhost:8080/","height":94}},"source":["learner.fit_one_cycle(config.epochs, max_lr=config.max_lr)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","                background: #F44336;\n","            }\n","        </style>\n","      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      0.00% [0/1 00:00<00:00]\n","    </div>\n","    \n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>epoch</th>\n","      <th>train_loss</th>\n","      <th>valid_loss</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>\n","\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","                background: #F44336;\n","            }\n","        </style>\n","      <progress value='785' class='' max='1312', style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      59.83% [785/1312 26:30<17:47 0.4952]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"AKeksHmt3pSz","colab_type":"code","colab":{}},"source":["help(learner)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8jmMKnAGrVzj","colab_type":"text"},"source":["See how simple that was?"]},{"cell_type":"code","metadata":{"id":"orJtitG1rVzk","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O_Mqdu_crVzl","colab_type":"text"},"source":["# Predictions"]},{"cell_type":"markdown","metadata":{"id":"RMU5bTB9rVzm","colab_type":"text"},"source":["Now to generate predictions. This is where you can get tripped up because the `databunch` does not load data in sorted order. So we'll have to do reorder the generated predictions to match their original order.\n","\n","如果您使用的是整个数据集，则需要一段时间。\n","训练完模型后，我们现在要生成预测。这可能有点棘手，因为预测生成仍然不如fastai的其他部分记录在案。我们必须要注意的是，数据加载器不会按排序顺序加载数据。这意味着我们必须对预测进行重新排序以匹配原始排序（此代码是从与文本相关的学习者代码中借用的）。"]},{"cell_type":"code","metadata":{"id":"VN2tymCArVzm","colab_type":"code","colab":{}},"source":["def get_preds_as_nparray(ds_type) -> np.ndarray:\n","    \"\"\"\n","    the get_preds method does not yield the elements in order by default\n","    we borrow the code from the RNNLearner to resort the elements into their correct order\n","    \"\"\"\n","    preds = learner.get_preds(ds_type)[0].detach().cpu().numpy()\n","    sampler = [i for i in databunch.dl(ds_type).sampler]\n","    reverse_sampler = np.argsort(sampler)\n","    return preds[reverse_sampler, :]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_QuLXyBArVzo","colab_type":"code","colab":{}},"source":["test_preds = get_preds_as_nparray(DatasetType.Test)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vAasqAAcrVzp","colab_type":"text"},"source":["You can generate a submission if you like, though you'll probably want to use a different set of configurations."]},{"cell_type":"code","metadata":{"id":"mzF0ONBirVzq","colab_type":"code","colab":{}},"source":["# sample_submission = pd.read_csv(DATA_ROOT / \"sample_submission.csv\")\n","# if config.testing: sample_submission = sample_submission.head(test.shape[0])\n","# sample_submission[label_cols] = test_preds\n","# sample_submission.to_csv(\"predictions.csv\", index=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P2t1heRXrVzs","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}